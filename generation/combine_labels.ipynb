{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3821f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47bbef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "# Use absolute paths or '.' if local. \n",
    "# 'os.path.abspath' below will fix the '.' ugliness automatically.\n",
    "ORIGINAL_DATA_ROOT = '.' \n",
    "ORIGINAL_CSV_PATH = os.path.join(ORIGINAL_DATA_ROOT, 'labels.csv')\n",
    "AUGMENTED_DATA_ROOT = 'augmented'\n",
    "OUTPUT_CSV_PATH = 'combined_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91544ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_csv():\n",
    "    print(\" Building Clean Master CSV...\")\n",
    "    \n",
    "    # --- 1. PROCESS ORIGINAL DATA ---\n",
    "    print(\"   Processing Original Dataset...\")\n",
    "    if os.path.exists(ORIGINAL_CSV_PATH):\n",
    "        df_orig = pd.read_csv(ORIGINAL_CSV_PATH)\n",
    "        df_orig.columns = [c.strip() for c in df_orig.columns]\n",
    "\n",
    "        # 1. Join path\n",
    "        # 2. normpath (cleans up A/./B stuff)\n",
    "        # 3. replace \\ with / (Enforces Linux style even on Windows)\n",
    "        df_orig['filepath'] = df_orig['pth'].apply(\n",
    "            lambda x: os.path.normpath(os.path.join(ORIGINAL_DATA_ROOT, x)).replace('\\\\', '/')\n",
    "        )\n",
    "        \n",
    "        df_orig['label'] = df_orig['label'].astype(str).str.strip().str.lower()\n",
    "        df_orig_clean = df_orig[['filepath', 'label']].copy()\n",
    "        df_orig_clean['source'] = 'original'\n",
    "        print(f\"   -> Added {len(df_orig_clean)} original images.\")\n",
    "    else:\n",
    "        print(\"   ️ Original CSV not found. Skipping.\")\n",
    "        df_orig_clean = pd.DataFrame()\n",
    "\n",
    "    # --- 2. PROCESS AUGMENTED DATA (Direct Folder Scan) ---\n",
    "    print(\"   Scanning Augmented Folders...\")\n",
    "    aug_data = []\n",
    "    \n",
    "    if os.path.exists(AUGMENTED_DATA_ROOT):\n",
    "        for root, dirs, files in os.walk(AUGMENTED_DATA_ROOT):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    folder_name = os.path.basename(root)\n",
    "                    label = folder_name.replace('aug_', '').lower()\n",
    "                    \n",
    "                    # LOGIC FIX:\n",
    "                    # os.path.join might create backslashes on Windows.\n",
    "                    # We force them to forward slashes immediately.\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    clean_path = os.path.normpath(full_path).replace('\\\\', '/')\n",
    "                    \n",
    "                    aug_data.append({\n",
    "                        'filepath': clean_path,\n",
    "                        'label': label,\n",
    "                        'source': 'augmented'\n",
    "                    })\n",
    "    else:\n",
    "        print(f\"   ️ Folder {AUGMENTED_DATA_ROOT} not found.\")\n",
    "\n",
    "    df_aug_clean = pd.DataFrame(aug_data)\n",
    "    print(f\"   -> Added {len(df_aug_clean)} augmented images.\")\n",
    "    \n",
    "    # --- 3. MERGE & SAVE ---\n",
    "    final_df = pd.concat([df_orig_clean, df_aug_clean], ignore_index=True)\n",
    "    \n",
    "    # Shuffle\n",
    "    final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    final_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\" DONE! Saved to: {OUTPUT_CSV_PATH}\")\n",
    "    print(f\"Sample paths:\")\n",
    "    print(final_df['filepath'].head(3).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ee30b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Building Clean Master CSV...\n",
      "   Processing Original Dataset...\n",
      "   -> Added 31002 original images.\n",
      "   Scanning Augmented Folders...\n",
      "   -> Added 8110 augmented images.\n",
      "------------------------------\n",
      " DONE! Saved to: combined_labels.csv\n",
      "Sample paths:\n",
      "['surprise/image0027442.jpg' 'sad/image0027758.jpg' 'sad/image0020564.jpg']\n"
     ]
    }
   ],
   "source": [
    "create_master_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730da094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows per unique label:\n",
      "label\n",
      "fear        4889\n",
      "sad         4889\n",
      "neutral     4889\n",
      "contempt    4889\n",
      "disgust     4889\n",
      "surprise    4889\n",
      "anger       4889\n",
      "happy       4889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count rows per unique value in \"augmented_label\" column of the CSV\n",
    "df_aug = pd.read_csv(\"combined_labels.csv\")\n",
    "target_col = 'label'\n",
    "# allow case-insensitive match\n",
    "cols_map = {c.lower(): c for c in df_aug.columns}\n",
    "if target_col not in cols_map:\n",
    "    print(f\"Column '{target_col}' not found. Available columns: {list(df_aug.columns)}\")\n",
    "else:\n",
    "    col = cols_map[target_col]\n",
    "    counts = df_aug[col].astype(str).str.strip().value_counts()\n",
    "    print(\"Number of rows per unique label:\")\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9580506d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total augmented rows: 8110\n",
      "Number of rows per unique label (augmented only):\n",
      "label\n",
      "neutral     1787\n",
      "sad         1537\n",
      "contempt    1301\n",
      "fear        1136\n",
      "disgust     1113\n",
      "anger        729\n",
      "happy        507\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count labels but only for rows where source == 'augmented' (case-insensitive)\n",
    "target_col = 'label'\n",
    "source_col = 'source'\n",
    "\n",
    "cols_map = {c.lower(): c for c in df_aug.columns}\n",
    "if target_col not in cols_map:\n",
    "    print(f\"Column '{target_col}' not found. Available columns: {list(df_aug.columns)}\")\n",
    "elif source_col not in cols_map:\n",
    "    print(f\"Column '{source_col}' not found. Available columns: {list(df_aug.columns)}\")\n",
    "else:\n",
    "    col = cols_map[target_col]\n",
    "    src = cols_map[source_col]\n",
    "    df_augmented = df_aug[df_aug[src].astype(str).str.strip().str.lower() == 'augmented']\n",
    "    print(f\"Total augmented rows: {len(df_augmented)}\")\n",
    "    counts = df_augmented[col].astype(str).str.strip().value_counts()\n",
    "    print(\"Number of rows per unique label (augmented only):\")\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3261c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
